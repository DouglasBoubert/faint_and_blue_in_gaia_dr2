{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Analyse the HVS survey data cross-matched with Gaia and Galex. \"\"\"\n",
    "\n",
    "##### Dependencies\n",
    "import numpy as np\n",
    "%matplotlib osx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord as coord\n",
    "import copy\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib.colors import LogNorm\n",
    "#plt.rc('text', usetex=True)\n",
    "#plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Options\n",
    "simplifyclasses = True\n",
    "if simplifyclasses == True:\n",
    "    type_unique = [-1,0,1]\n",
    "    type_text = ['QSO','B/BHB','WD']\n",
    "    type_colors = ['limegreen','deepskyblue','orangered']\n",
    "else:\n",
    "    type_unique = [-2,-1,0,1,2,3,7]\n",
    "    type_text = ['cont','QSO','B/BHB','DA','DZ','DB','Weird']\n",
    "    type_colors = ['limegreen','greenyellow','deepskyblue','orangered','red','darkred','darkorchid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandict(DICT,STRING):\n",
    "    ### Remove all columns in DICT which start with string.\n",
    "    nSTRING = len(STRING)\n",
    "    copyDICT = copy.deepcopy(DICT)\n",
    "    for k,v in DICT.items():\n",
    "        if k[:nSTRING] == STRING:\n",
    "            del copyDICT[k]\n",
    "    return copyDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load in HVS data\n",
    "hvsdata = np.load('/Users/douglasboubert/Documents/Science/GaiaDR2/HVSsurvey/data/gagahvs.npz')\n",
    "locals().update(hvsdata)\n",
    "gagahvsbox=gagahvsbox.item()\n",
    "\n",
    "##### Simplify classes\n",
    "nhvs = gagahvsbox['ra'].shape[0]\n",
    "HVSCLASS = gagahvsbox['hvswd']\n",
    "\n",
    "if simplifyclasses:\n",
    "    HVSCLASS[HVSCLASS ==  2] =  1 # DZ -> DA\n",
    "    HVSCLASS[HVSCLASS ==  3] =  1 # DB -> DA\n",
    "    HVSCLASS[HVSCLASS == -2] = -1 # cont -> QSO\n",
    "    HVSCLASS[HVSCLASS ==  7] =  0 # Weird -> B/BHB\n",
    "    \n",
    "gagahvsbox['CLASS'] = HVSCLASS\n",
    "gagahvsbox['u_g0'] = gagahvsbox['hvsug0']\n",
    "gagahvsbox['g_r0'] = gagahvsbox['hvsgr0']\n",
    "#gagahvsbox['r_i0'] = gagahvsbox['hvsri0']\n",
    "\n",
    "gagahvsbox = cleandict(gagahvsbox,'hvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load in BHB data\n",
    "bhbdata = np.load('/Users/douglasboubert/Documents/Science/GaiaDR2/HVSsurvey/data/gagabhb.npz')\n",
    "locals().update(bhbdata)\n",
    "gagabhbbox=gagabhbbox.item()\n",
    "\n",
    "##### Simplify classes\n",
    "nbhb = gagabhbbox['ra'].shape[0]\n",
    "BHBCLASS = 0.0*np.ones(nbhb)\n",
    "    \n",
    "gagabhbbox['CLASS'] = BHBCLASS\n",
    "gagabhbbox['u_g0'] = gagabhbbox['bhbu-g']\n",
    "gagabhbbox['g_r0'] = gagabhbbox['bhbg-r']\n",
    "\n",
    "gagabhbbox = cleandict(gagabhbbox,'bhb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load in WD data\n",
    "wddata = np.load('/Users/douglasboubert/Documents/Science/GaiaDR2/HVSsurvey/data/gagawd.npz')\n",
    "locals().update(wddata)\n",
    "gagawdbox=gagawdbox.item()\n",
    "\n",
    "##### Simplify classes\n",
    "nwd = gagawdbox['ra'].shape[0]\n",
    "wdclass_string = gagawdbox['wdCLASS']\n",
    "wdclass = np.array([wdclass_string[i][-1] for i in range(nwd)])\n",
    "WDCLASS = np.zeros(nwd)\n",
    "\n",
    "WDTYPES = ['A','B','C','O','Q','X','Z']\n",
    "if simplifyclasses:\n",
    "    WDCLASSIFICATIONS = [1,1,1,1,1,1,1]\n",
    "else:\n",
    "    WDCLASSIFICATIONS = [1,3,7,7,7,7,2]\n",
    "\n",
    "for wdt,wdc in zip(WDTYPES,WDCLASSIFICATIONS):\n",
    "    WDCLASS[wdclass ==  wdt] =  wdc\n",
    "    \n",
    "gagawdbox['CLASS'] = WDCLASS\n",
    "gagawdbox['u_g0'] = gagawdbox['wdUMAG']-gagawdbox['wdGMAG']\n",
    "gagawdbox['g_r0'] = gagawdbox['wdGMAG']-gagawdbox['wdRMAG']\n",
    "\n",
    "gagawdbox = cleandict(gagawdbox,'wd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load in QSO data\n",
    "qsodata = np.load('/Users/douglasboubert/Documents/Science/GaiaDR2/HVSsurvey/data/gagaqso.npz')\n",
    "locals().update(qsodata)\n",
    "gagaqsobox=gagaqsobox.item()\n",
    "\n",
    "##### Simplify classes\n",
    "nqso = gagaqsobox['ra'].shape[0]\n",
    "QSOCLASS = -1.0*np.ones(nqso)\n",
    "    \n",
    "gagaqsobox['CLASS'] = QSOCLASS\n",
    "gagaqsobox['u_g0'] = gagaqsobox['qsoug0']\n",
    "gagaqsobox['g_r0'] = gagaqsobox['qsogr0']\n",
    "\n",
    "gagaqsobox = cleandict(gagaqsobox,'qso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Form merged dict\n",
    "randomorder = np.random.choice(range(nhvs+nbhb+nwd+nqso),nhvs+nbhb+nwd+nqso,replace=False)\n",
    "gagabox = {k:np.hstack([gagahvsbox[k],gagabhbbox[k],gagawdbox[k],gagaqsobox[k]])[randomorder] for k in gagahvsbox.keys()}\n",
    "N = gagabox['ra'].shape[0]\n",
    "\n",
    "### Correct FUV mag\n",
    "gagabox['fuv_mag'] = np.array([float(fuv) if fuv != 'None' else np.nan for fuv in gagabox['fuv_mag']])\n",
    "gagabox['fuv_magerr'] = np.array([float(fuv) if fuv != 'None' else np.nan for fuv in gagabox['fuv_magerr']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All stars\t\t\t 28982\n",
      "Has Gaia crossmatch\t\t 21008\n",
      "Has Gaia color crossmatch\t 19905\n",
      "Has Gaia ast color crossmatch\t 17985\n",
      "Has Galex crossmatch\t\t 13535\n",
      "Has Allwise crossmatch\t\t 21019\n",
      "Has GaAl ast color crossmatch\t 14400\n",
      "Has GaGa crossmatch\t\t 11766\n",
      "Has GaGa color crossmatch\t 11417\n",
      "Has GaGaAst crossmatch\t\t 10817\n",
      "Has GaGaAstColor crossmatch\t 10768\n"
     ]
    }
   ],
   "source": [
    "hasgaiacrossmatch = np.where(np.isnan(gagabox['phot_g_mean_mag'])==False)\n",
    "hasgaiacolorcrossmatch = np.where(np.isnan(gagabox['phot_bp_mean_mag'])==False)\n",
    "hasgaiaastcolorcrossmatch = np.where((np.isnan(gagabox['phot_bp_mean_mag'])==False) & (np.isnan(gagabox['parallax'])==False))\n",
    "hasgalexcrossmatch = np.where(np.isnan(gagabox['nuv_mag'])==False)\n",
    "hasallwisecrossmatch = np.where(np.isnan(gagabox['w1mpro'])==False)\n",
    "hasgaalastcolorcrossmatch = np.where((np.isnan(gagabox['phot_bp_mean_mag'])==False) & (np.isnan(gagabox['w1mpro'])==False) & (np.isnan(gagabox['w2mpro'])==False) & (np.isnan(gagabox['parallax'])==False))\n",
    "hasgagacrossmatch = np.where((np.isnan(gagabox['nuv_mag'])==False)&(np.isnan(gagabox['phot_g_mean_mag'])==False))\n",
    "hasgagacolorcrossmatch = np.where((np.isnan(gagabox['nuv_mag'])==False)&(np.isnan(gagabox['phot_bp_mean_mag'])==False))\n",
    "hasgagaastcrossmatch = np.where((np.isnan(gagabox['nuv_mag'])==False)&(np.isnan(gagabox['parallax'])==False))\n",
    "hasgagaastcolorcrossmatch = np.where((np.isnan(gagabox['nuv_mag'])==False)&(np.isnan(gagabox['parallax'])==False)&(np.isnan(gagabox['phot_bp_mean_mag'])==False))\n",
    "print('All stars\\t\\t\\t',gagabox['phot_g_mean_mag'].shape[0])\n",
    "print(\"Has Gaia crossmatch\\t\\t\",hasgaiacrossmatch[0].shape[0])\n",
    "print(\"Has Gaia color crossmatch\\t\",hasgaiacolorcrossmatch[0].shape[0])\n",
    "print(\"Has Gaia ast color crossmatch\\t\",hasgaiaastcolorcrossmatch[0].shape[0])\n",
    "print('Has Galex crossmatch\\t\\t',hasgalexcrossmatch[0].shape[0])\n",
    "print('Has Allwise crossmatch\\t\\t',hasallwisecrossmatch[0].shape[0])\n",
    "print('Has GaAl ast color crossmatch\\t',hasgaalastcolorcrossmatch[0].shape[0])\n",
    "print('Has GaGa crossmatch\\t\\t',hasgagacrossmatch[0].shape[0])\n",
    "print('Has GaGa color crossmatch\\t',hasgagacolorcrossmatch[0].shape[0])\n",
    "print('Has GaGaAst crossmatch\\t\\t',hasgagaastcrossmatch[0].shape[0])\n",
    "print('Has GaGaAstColor crossmatch\\t',hasgagaastcolorcrossmatch[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-matched 27 out of 30\n"
     ]
    }
   ],
   "source": [
    "##### Load in true hypervelocity stars\n",
    "hvsdata = pd.read_csv('/Users/douglasboubert/Documents/Science/GaiaDR2/HVSsurvey/data/hypervelocitystars18052018.csv')\n",
    "hvsradec = np.array( [ hvsdata['R.A.'][i].split(',')[0]+hvsdata['Dec.'][i].split(',')[0] for i in range(len(hvsdata['R.A.']))] )\n",
    "hvscoord = coord(hvsradec,unit=(u.hourangle, u.deg))\n",
    "hvsra = hvscoord.ra.deg\n",
    "hvsdec = hvscoord.dec.deg\n",
    "\n",
    "##### Cross-match true hypervelocity stars with HVS survey\n",
    "# Small enough that we can do this naively.\n",
    "dtr = np.pi/180.0\n",
    "skysep = (3600/dtr)*np.arccos(np.sin(gagabox['dec']*dtr)*np.sin(hvsdec[:,np.newaxis]*dtr)+np.cos(gagabox['dec']*dtr)*np.cos(hvsdec[:,np.newaxis]*dtr)*np.cos((gagabox['ra']-hvsra[:,np.newaxis])*dtr)).T\n",
    "skysep[np.isnan(skysep)==True]=1e10\n",
    "minskysep = np.min(skysep,axis=1)\n",
    "ishvs = np.where(minskysep<1)\n",
    "\n",
    "##### Check the cross-match worked\n",
    "# Check that these are all B stars\n",
    "assert np.array_equal(gagabox['CLASS'][ishvs],np.zeros(ishvs[0].shape[0]))\n",
    "# Print number found\n",
    "print('Cross-matched',ishvs[0].shape[0],'out of',hvsra.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Labels\n",
    "n_type = len(type_unique)\n",
    "type_index = []\n",
    "for TYPE in type_unique:\n",
    "    type_index.append(np.where(gagabox['CLASS']==TYPE))\n",
    "\n",
    "##### Type plotting\n",
    "def type_plotting(X,Y,XSTR=None,YSTR=None,PLOT=False,PLOTHVS=False,BOX=gagabox,PLOTTYPES=None):\n",
    "    if isinstance(X,str):\n",
    "        U = BOX[X]\n",
    "        XSTR = X\n",
    "    else:\n",
    "        U = X\n",
    "    if isinstance(Y,str):\n",
    "        V = BOX[Y]\n",
    "        YSTR = Y\n",
    "    else:\n",
    "        V = Y\n",
    "        \n",
    "    if PLOTTYPES == None:\n",
    "        PLOTTYPES = type_unique\n",
    "    for i in range(n_type):\n",
    "        if type_unique[i] in PLOTTYPES:\n",
    "            plt.scatter(U[type_index[i]],V[type_index[i]],c=type_colors[i],label=type_text[i],alpha=0.5)\n",
    "    if PLOTHVS == True:\n",
    "        plt.scatter(U[ishvs],V[ishvs],label='HVS',marker='*',c='k')\n",
    "    if PLOT == True:\n",
    "        plt.xlabel(XSTR)\n",
    "        plt.ylabel(YSTR)\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### However astrometry is good enough\n",
    "total_pm = np.sqrt(gagabox['pmra']**2+gagabox['pmdec']**2.)\n",
    "type_plotting(np.log10(total_pm),'phot_g_mean_mag',PLOTHVS=True)\n",
    "#plt.scatter(totalpm[type_index[2]],gagabox['phot_g_mean_mag'][type_index[2]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### However astrometry is good enough\n",
    "total_pm = np.sqrt(gagabox['pmra']**2+gagabox['pmdec']**2.)\n",
    "type_plotting(np.log10(totalpm),gagabox['w1mpro']-gagabox['w2mpro'],PLOTHVS=True)\n",
    "#plt.scatter(totalpm[type_index[2]],gagabox['phot_g_mean_mag'][type_index[2]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_plotting('bp_g','g_rp',PLOTHVS=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Form new colour space\n",
    "# Inputs\n",
    "impute_magnitudes = [gagabox['phot_g_mean_mag'],gagabox['phot_bp_mean_mag'],gagabox['phot_rp_mean_mag'],gagabox['fuv_mag'],gagabox['nuv_mag'],gagabox['w1mpro'],gagabox['w2mpro']]\n",
    "impute_magnitudes_error = [np.ones(N)*0.1,np.ones(N)*0.1,np.ones(N)*0.1,gagabox['fuv_magerr'],gagabox['nuv_magerr'],gagabox['w1sigmpro'],gagabox['w2sigmpro']]\n",
    "impute_labels = ['g','bp','rp','nuv','fuv','w1','w2']\n",
    "impute_A = [0.,0.,0.,3.77,3.39,0,0] # GALEX https://arxiv.org/abs/1805.08951\n",
    "impute_N = len(impute_labels)\n",
    "impute_Nlim = 6\n",
    "\n",
    "# Correct for dust\n",
    "impute_magnitudes_0 = [impute_magnitudes[i]-gagabox['ebv']*impute_A[i] for i in range(impute_N)]\n",
    "\n",
    "\n",
    "\n",
    "# Samples with all magnitudes\n",
    "hasallcolors = np.where((np.isnan(gagabox['phot_bp_mean_mag'])==False)&(np.isnan(gagabox['nuv_mag'])==False)&(np.isnan(gagabox['fuv_mag'])==False)&(np.isnan(gagabox['w1mpro'])==False)&(np.isnan(gagabox['w2mpro'])==False))\n",
    "\n",
    "# Function to impute\n",
    "def imputer(MAG1,MAG2):\n",
    "    TMP = MAG1-MAG2\n",
    "    TMP[np.isnan(TMP)==True] = np.median(TMP[np.isnan(TMP)==False])\n",
    "    return TMP\n",
    "\n",
    "# Form dictionary of colors\n",
    "colorbox={}\n",
    "for I in range(impute_N):\n",
    "    for J in range(I+1,impute_N):\n",
    "        implabel = impute_labels[I]+'_'+impute_labels[J]\n",
    "        colorbox[implabel] = imputer(impute_magnitudes_0[I],impute_magnitudes_0[J])\n",
    "colorkeys = list(colorbox.keys())\n",
    "colorkeys.sort()\n",
    "\n",
    "# Form input to PCA\n",
    "Nck = len(colorkeys)\n",
    "Xcolor = np.zeros((N,Nck))\n",
    "for i in range(Nck):\n",
    "    Xcolor[:,i] = colorbox[colorkeys[i]]\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=impute_Nlim, svd_solver='full',whiten=True)\n",
    "if False:\n",
    "    Xcolor_pca = pca.fit_transform(Xcolor)\n",
    "else:\n",
    "    pca.fit(Xcolor[hasallcolors])\n",
    "    Xcolor_pca = pca.transform(Xcolor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use marginalisation for imputation!\n",
    "# Do it in magnitudes to avoid correlations\n",
    "# Should be analytic!\n",
    "\n",
    "# Form variable containing dereddened magnitudes and errors\n",
    "Xmag_mu = np.array(impute_magnitudes_0).T\n",
    "Xmag_error = np.array(impute_magnitudes_error).T\n",
    "\n",
    "# Correct NaNs\n",
    "Xmag_mu[np.isnan(Xmag_mu)==True] = 0.0\n",
    "Xmag_error[np.isnan(Xmag_error)==True] = 10.\n",
    "Xmag_var = np.power(Xmag_error,2.0)\n",
    "\n",
    "# Form colours with covariance matrix\n",
    "def offdiag_indices(n,k):\n",
    "    rows, cols = np.indices((n,n))\n",
    "    return np.diag(rows, k=k), np.diag(cols, k=k)\n",
    "#Xcol_mu = (Xmag[:,:,np.newaxis]-Xmag[:,np.newaxis,:])[:,np.triu_indices(7,1)[0],np.triu_indices(7,1)[1]]\n",
    "NXcol = Xcol_mu.shape[1]\n",
    "Xcol_mu = Xmag_mu-np.roll(Xmag_mu,-1,axis=1)\n",
    "Xcol_cov = np.zeros((N,NXcol,NXcol))\n",
    "Xcol_cov[:,np.diag_indices(NXcol)[0],np.diag_indices(NXcol)[1]] = Xmag_var+np.roll(Xmag_var,-1,axis=1)\n",
    "Xcol_cov[:,offdiag_indices(NXcol,1)[0],offdiag_indices(NXcol,1)[1]] = Xmag_var[:,1:]\n",
    "Xcol_cov[:,offdiag_indices(NXcol,-1)[0],offdiag_indices(NXcol,-1)[1]] = Xmag_var[:,1:]\n",
    "Xcol_cov[:,0,NXcol-1] = Xcol_cov[:,NXcol-1,0] = Xmag_var[:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.20739937, 19.20890045, 18.88120079,  0.        , 20.23370736,\n",
       "       16.71500015, 16.48600006])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xmag_mu[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-02, 1.00000000e-02, 1.00000000e-02, 1.00000000e+02,\n",
       "       3.30843359e-02, 9.40900056e-03, 7.89609934e-02])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xmag_var[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.50108337e-03,  3.27699661e-01,  1.88812008e+01, -2.02337074e+01,\n",
       "        3.51870720e+00,  2.29000092e-01, -2.72139931e+00])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcol_mu[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00000000e-02, 2.00000000e-02, 1.00010000e+02, 1.00033084e+02,\n",
       "       4.24933364e-02, 8.83699940e-02, 8.89609934e-02])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(Xcol_cov[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999966318"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(Xcol_invcov[19],Xcol_cov[19])[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate z_c,mu_c,cov_c\n",
    "i=19\n",
    "Xcol_invcov = np.linalg.inv(Xcol_cov)\n",
    "Xcol_covi = Xcol_cov+Xcol_cov[i]\n",
    "Xcol_mui = Xcol_mu[i]-Xcol_mu\n",
    "lnZ_c = -0.5*np.einsum('ni,nij,nj->n',Xcol_mui,np.linalg.inv(Xcol_covi),Xcol_mui)-0.5*np.log(np.linalg.det(2.0*np.pi*Xcol_covi))\n",
    "cov_c = np.linalg.inv(Xcol_invcov[i]+Xcol_invcov)\n",
    "mu_c = np.einsum('nij,jk,k->ni',cov_c,Xcol_invcov[i],Xcol_mu[i])+np.einsum('nij,njk,nk->ni',cov_c,Xcol_invcov,Xcol_mu)\n",
    "noti = np.setdiff1d(range(N),i)\n",
    "norm_c = np.sum(np.exp(lnZ_c[noti]))\n",
    "mu_new = np.sum((mu_c*np.exp(lnZ_c[:,np.newaxis]))[noti],axis=0)/norm_c\n",
    "cov_new = np.sum((cov_c*np.exp(lnZ_c[:,np.newaxis,np.newaxis]))[noti],axis=0)/norm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/douglasboubert/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  del sys.path[0]\n",
      "/Users/douglasboubert/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Users/douglasboubert/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate z_c,mu_c,cov_c\n",
    "i=19\n",
    "Xcol_covi = Xcol_cov+Xcol_cov[i]\n",
    "Xcol_invcovi = np.linalg.inv(Xcol_covi)\n",
    "Xcol_mui = Xcol_mu[i]-Xcol_mu\n",
    "lnZ_c = -0.5*np.einsum('ni,nij,nj->n',Xcol_mui,np.linalg.inv(Xcol_covi),Xcol_mui)-0.5*np.log(np.linalg.det(2.0*np.pi*Xcol_covi))\n",
    "cov_c = np.einsum('ij,njk,nkl->nil',Xcol_cov[i],Xcol_invcovi,Xcol_cov)\n",
    "mu_c = np.einsum('ij,njk,nk->ni',Xcol_cov[i],Xcol_invcovi,Xcol_mu)+np.einsum('nij,njk,k->ni',cov_c,Xcol_invcovi,Xcol_mu[i])\n",
    "#noti = np.setdiff1d(range(N),i)\n",
    "noti = np.setdiff1d(hasallcolors,i)\n",
    "from scipy.special import logsumexp\n",
    "norm_c = logsumexp(lnZ_c[noti])\n",
    "mu_new = np.sum((mu_c*np.exp(lnZ_c[:,np.newaxis]-norm_c))[noti],axis=0)\n",
    "cov_new = np.sum((cov_c*np.exp(lnZ_c[:,np.newaxis,np.newaxis]-norm_c))[noti],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3948"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax((lnZ_c-norm_c)[noti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.10892439, -0.12557459,  6.46623582, -0.67618031, -1.81709532,\n",
       "        -5.8841841 , -0.32901438]),\n",
       " array([-1.50108337e-03,  3.27699661e-01,  1.88812008e+01, -2.02337074e+01,\n",
       "         3.51870720e+00,  2.29000092e-01, -2.72139931e+00]))"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_new,Xcol_mu[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.09999084e-03,  8.62998962e-02,  1.75240002e+01,  0.00000000e+00,\n",
       "       -1.72700005e+01,  5.64001083e-01, -9.02200699e-01])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcol_mu[3948]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0332556 ,  0.26475234, -1.28971078,  0.11507847,  2.32088157,\n",
       "        0.33618929, -1.71393529])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcol_mu.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.24794473,  0.23509676, -1.01284798],\n",
       "       [ 0.23509676,  2.57700245,  2.34190569],\n",
       "       [-1.01284798,  2.34190569,  3.35475367]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsamp = 10000\n",
    "a = np.random.normal(1.,0.5,nsamp)\n",
    "b = np.random.normal(2.,1.0,nsamp)\n",
    "c = np.random.normal(3.,1.5,nsamp)\n",
    "ab = a-b\n",
    "ac = a-c\n",
    "bc = b-c\n",
    "plt.scatter(ab,ac)\n",
    "np.cov(np.vstack([ab,ac,bc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28982, 21)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.57527363, 17.89483799,  0.78479179,  0.49750243,  0.14838423,\n",
       "        0.02960642])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_w2 0.3811623226165086\n",
      "bp_w2 0.3801481470033788\n",
      "rp_w2 0.352730363599096\n",
      "g_w1 0.3191410129365432\n",
      "bp_w1 0.3181268373234134\n",
      "rp_w1 0.29070905391913066\n",
      "fuv_w2 0.2763916208079594\n",
      "nuv_w2 0.24467436113290617\n",
      "fuv_w1 0.21437031112799407\n",
      "nuv_w1 0.18265305145294078\n",
      "g_nuv 0.13648796148360245\n",
      "bp_nuv 0.13547378587047254\n",
      "rp_nuv 0.10805600246618982\n",
      "g_fuv 0.10477070180854922\n",
      "bp_fuv 0.10375652619541934\n",
      "rp_fuv 0.07633874279113644\n",
      "w1_w2 0.06202130967996537\n",
      "g_rp 0.028431959017412665\n",
      "bp_rp 0.027417783404282692\n",
      "g_bp 0.001014175613129882\n",
      "nuv_fuv -0.03171725967505331\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for i in np.argsort(pca.components_[j])[::-1]:\n",
    "    print(colorkeys[i],pca.components_[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting astrometric_pseudo_colour\n",
      "deleting astrometric_pseudo_colour_error\n",
      "TypeError on phot_variable_flag\n",
      "deleting a_g_val\n",
      "deleting e_bp_min_rp_val\n",
      "deleting radial_velocity\n",
      "deleting radial_velocity_error\n",
      "deleting rv_template_teff\n",
      "deleting rv_template_logg\n",
      "deleting rv_template_fe_h\n",
      "deleting galex_ra\n",
      "deleting galex_dec\n",
      "deleting fuv_mag\n",
      "TypeError on fuv_magerr\n",
      "deleting nuv_mag\n",
      "deleting nuv_magerr\n",
      "deleting allwise_ra\n",
      "deleting allwise_dec\n",
      "deleting w1mpro\n",
      "deleting w1sigmpro\n",
      "deleting w2mpro\n",
      "deleting w2sigmpro\n"
     ]
    }
   ],
   "source": [
    "##### Machine learning\n",
    "# Select clean features\n",
    "\n",
    "removefeatures = ['source_id','u_g0','g_r0','CLASS','log10_total_pm','ra','dec','bp_rp','g_rp','bp_g']\n",
    "#subsetofstars = hasgagaastcolorcrossmatch\n",
    "subsetofstars = hasgaiaastcolorcrossmatch\n",
    "#subsetofstars = hasgaalastcolorcrossmatch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "featurebox = {k:v[subsetofstars] for k, v in gagabox.items()}\n",
    "y = featurebox['CLASS']\n",
    "\n",
    "### Add features\n",
    "hasallwise = np.zeros(N)\n",
    "hasallwise[hasallwisecrossmatch] = 1.0\n",
    "hasgalex = np.zeros(N)\n",
    "hasgalex[hasgalexcrossmatch] = 1.0\n",
    "reduced_pm = gagabox['phot_g_mean_mag']-5.*5.*np.log10(total_pm)\n",
    "total_pm_over_error = total_pm**2./np.sqrt((gagabox['pmra']*gagabox['pmra_error'])**2+(gagabox['pmdec']*gagabox['pmra_error'])**2.-gagabox['pmra_pmdec_corr']*gagabox['pmra']*gagabox['pmdec']*gagabox['pmra_error']*gagabox['pmdec_error'])\n",
    "\n",
    "\n",
    "if True:\n",
    "    addfeatures_keys = ['total_pm_over_error','reduced_pm','total_pm','log10_total_pm','vt','g_variability','bp_variablity','rp_variability','hasallwise','hasgalex','abs_b']\n",
    "    addfeatures_values = [total_pm_over_error,reduced_pm,total_pm,np.log10(total_pm),np.abs(totalpm/gagabox['parallax']),np.log10(np.sqrt(gagabox['phot_g_n_obs']/gagabox['phot_g_mean_flux_over_error'])),np.log10(np.sqrt(gagabox['phot_bp_n_obs']/gagabox['phot_bp_mean_flux_over_error'])),np.log10(np.sqrt(gagabox['phot_rp_n_obs']/gagabox['phot_rp_mean_flux_over_error'])),hasallwise,hasgalex,np.abs(gagabox['b'])]\n",
    "    \n",
    "    for i in range(len(addfeatures_keys)):\n",
    "        featurebox[addfeatures_keys[i]] = addfeatures_values[i][subsetofstars]\n",
    "\n",
    "# Add imputed colors\n",
    "if True:\n",
    "    for i in range(impute_Nlim):\n",
    "        featurebox['impute_color_'+str(i)]=Xcolor_pca[subsetofstars,i].ravel()\n",
    "\n",
    "removehvsfeatures = True\n",
    "deletelist = []\n",
    "import copy\n",
    "copybox = copy.deepcopy(featurebox)\n",
    "for k, v in copybox.items():\n",
    "    try:\n",
    "        if np.isnan(v).any():\n",
    "            print('deleting',k)\n",
    "            deletelist.append(k)\n",
    "            del featurebox[k]\n",
    "        elif removehvsfeatures and k[:3]=='hvs':\n",
    "            print('removing HVS survey feature',k)\n",
    "            deletelist.append(k)\n",
    "            del featurebox[k]\n",
    "    except TypeError:\n",
    "        print('TypeError on',k)\n",
    "        deletelist.append('k')\n",
    "        del featurebox[k]\n",
    "for RF in removefeatures:\n",
    "    del featurebox[RF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form training and testing sets\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from random import shuffle\n",
    "v = DictVectorizer(sparse=False)\n",
    "D = [dict(zip(featurebox,t)) for t in zip(*featurebox.values())]\n",
    "#shuffle(D)\n",
    "X = v.fit_transform(D)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting [0.97741159 0.00205139]\n",
      "Extra Trees [0.9706006  0.00176515]\n",
      "Random Forest [0.97581345 0.00289398]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "GB = GradientBoostingClassifier(n_estimators=100)\n",
    "ET = ExtraTreesClassifier(n_estimators=100)\n",
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "#AB = AdaBoostClassifier(n_estimators=500)\n",
    "#VOT = VotingClassifier(estimators=[('gb', GB), ('et', ET), ('rf', RF)], voting='hard')\n",
    "CL = [GB,ET,RF]\n",
    "CL_names = ['Gradient Boosting', 'Extra Trees', 'Random Forest']\n",
    "CL_score = np.zeros((len(CL),2))\n",
    "for i, cl in zip(range(len(CL)),CL):\n",
    "    scores = cross_val_score(cl, X_train, y_train, cv=5,n_jobs=-1)\n",
    "    #cl.fit(X_train, y_train)\n",
    "    #CL_score[i] = cl.score(X_test,y_test)\n",
    "    CL_score[i] = scores.mean(), scores.std()\n",
    "    print(CL_names[i],CL_score[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting [0.97815751 0.00215111]\n",
    "Extra Trees [0.97423625 0.00357049]\n",
    "Random Forest [0.97591729 0.001703  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705309980539338"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=500,class_weight='balanced')\n",
    "#GB = GradientBoostingClassifier(n_estimators=500)\n",
    "CL_best = RF\n",
    "CL_best.fit(X_train, y_train)\n",
    "CL_best.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsgrid = np.arange(-1.5,2.0,1.0)\n",
    "midbins = (binsgrid[1:]+binsgrid[:-1])/2.0\n",
    "plt.figure(figsize=(6,5.8))\n",
    "hist = plt.hist2d(y_test,CL_best.predict(X_test),bins=[binsgrid,binsgrid],cmin=1,norm=LogNorm(),cmap=plt.cm.Greys,alpha=0.5)[0]\n",
    "for i,j in zip(np.where(np.isnan(hist)==False)[0],np.where(np.isnan(hist)==False)[1]):\n",
    "    plt.text(midbins[i],midbins[j],str(int(hist[i,j])),horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "plt.gca().set_xticks(type_unique)\n",
    "plt.gca().set_xticklabels(type_text)\n",
    "plt.gca().set_yticks(type_unique)\n",
    "plt.gca().set_yticklabels(type_text)\n",
    "#plt.axis('equal')\n",
    "#plt.colorbar()\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.xlim([-1.5,1.5])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/douglasboubert/Dropbox/ShowAndTell/GAIAhypervelocity/gaiabstar/result/machinelearning/confusion.pdf')\n",
    "plt.savefig('/Users/douglasboubert/Dropbox/ShowAndTell/GAIAhypervelocity/gaiabstar/result/machinelearning/confusion.png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_col(STR):\n",
    "    keys = np.array(list(D[0].keys()))\n",
    "    keys.sort()\n",
    "    retcolind = np.where(keys==STR)[0][0]\n",
    "    return retcolind\n",
    "def misclass(TRUEI,PREDI):\n",
    "    return np.where((CL_best.predict(X_test)==PREDI) & (y_test==TRUEI))\n",
    "def misclass_col(TI,PI,COLSTR):\n",
    "    return X_train[misclass(TI,PI),acquire_col(COLSTR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a14a78be0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Misclassified QSOs as BHBs\n",
    "\n",
    "misclass_qso_bhb = np.where((CL_best.predict(X_test)==0.) & (y_test==-1.))\n",
    "misclass_qso_qso = np.where((CL_best.predict(X_test)==-1.) & (y_test==-1.))\n",
    "plt.scatter(np.log10(X_train[:,acquire_col('total_pm')]),X_train[:,acquire_col('impute_color_0')],c=y_train,cmap=plt.cm.jet)\n",
    "#plt.scatter(np.log10(X_test[misclass_qso_qso,acquire_col('total_pm')]),X_test[misclass_qso_qso,acquire_col('impute_color_0')],c='violet',s=30)\n",
    "#plt.scatter(np.log10(X_test[misclass_qso_bhb,acquire_col('total_pm')]),X_test[misclass_qso_bhb,acquire_col('impute_color_0')],c='k',s=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.62611804,  3.81387715,  0.92382589,  0.65993441,  4.28232617,\n",
       "         0.599063  ,  0.41053167,  1.61070612,  6.44400381, 27.81069922,\n",
       "         3.42687073,  1.46534796,  3.84620067,  6.40230128,  5.54595107,\n",
       "         1.43464254,  2.50864718,  0.7317415 ,  3.5844266 ,  1.52830824,\n",
       "         7.85678732,  1.34673505,  2.66322569,  3.35185066,  4.40684354,\n",
       "         2.22793247,  1.99663372,  2.91365683,  8.02998789,  2.4621277 ,\n",
       "         3.86020613,  0.95087469,  1.67135356,  3.60713434,  1.08714329,\n",
       "        17.94263586,  8.60695917,  1.84529333,  1.30304664]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_col(1,-1,'total_pm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_pm 0.09474768590882512\n",
      "total_pm_over_error 0.09257748990024087\n",
      "reduced_pm 0.07891054217995815\n",
      "parallax 0.0748512438486473\n",
      "parallax_over_error 0.07428365572841636\n",
      "impute_color_0 0.044215786281774604\n",
      "phot_bp_mean_mag 0.029794612844414932\n",
      "phot_bp_mean_flux 0.029782567540689593\n",
      "pmdec 0.02729894752653744\n",
      "phot_g_mean_flux_over_error 0.025888668544875478\n",
      "astrometric_weight_al 0.023864216474081348\n",
      "g_variability 0.02382342488846023\n",
      "phot_g_mean_flux 0.02339351352021951\n",
      "hasallwise 0.023286901062807404\n",
      "impute_color_4 0.02194742913986881\n",
      "phot_g_mean_mag 0.02181749019498849\n",
      "phot_bp_rp_excess_factor 0.021655694403593044\n",
      "impute_color_1 0.02133605417102638\n",
      "phot_rp_mean_flux 0.0205433421701089\n",
      "phot_rp_mean_mag 0.020150402528989354\n",
      "pmra 0.018257903605348003\n",
      "impute_color_3 0.017058704933738487\n",
      "phot_bp_mean_flux_over_error 0.014327803431748358\n",
      "vt 0.011881826548800264\n",
      "bp_variablity 0.010589684601619529\n",
      "frame_rotator_object_type 0.010357455094112797\n",
      "dec_error 0.009903067055987149\n",
      "pmdec_error 0.009617212097495557\n",
      "parallax_error 0.00958638855412158\n",
      "ra_error 0.009240807005257513\n",
      "astrometric_sigma5d_max 0.007854289714818259\n",
      "impute_color_5 0.0075210209049734415\n",
      "pmra_error 0.007151379473491583\n",
      "phot_rp_mean_flux_over_error 0.0058255167265360425\n",
      "impute_color_2 0.004858324846828908\n",
      "rp_variability 0.003997468646148553\n",
      "hasgalex 0.0036655219105986995\n",
      "astrometric_primary_flag 0.0035996696355311613\n",
      "phot_g_mean_flux_error 0.003534055415582642\n",
      "l 0.0024340682820580863\n",
      "ebv 0.0019239890519236233\n",
      "abs_b 0.0018391577373828944\n",
      "phot_bp_mean_flux_error 0.0015193081611967947\n",
      "astrometric_gof_al 0.0014847792029019351\n",
      "phot_rp_mean_flux_error 0.0014843354846014914\n",
      "mean_varpi_factor_al 0.001475506189042857\n",
      "b 0.001425524774859837\n",
      "astrometric_chi2_al 0.0013245648127310158\n",
      "parallax_pmdec_corr 0.0013098992999899708\n",
      "ra_dec_corr 0.0012959708448550477\n",
      "ra_parallax_corr 0.001247243232459627\n",
      "dec_pmra_corr 0.0012453641048763644\n",
      "pmra_pmdec_corr 0.0012443783731479778\n",
      "ra_pmra_corr 0.0012399771469511398\n",
      "dec_parallax_corr 0.0012372240234841086\n",
      "parallax_pmra_corr 0.0012189625147440968\n",
      "ra_pmdec_corr 0.0012179645743480108\n",
      "phot_g_n_obs 0.0011284959108485396\n",
      "astrometric_n_obs_al 0.0011249034141729399\n",
      "dec_pmdec_corr 0.0010858628466333042\n",
      "astrometric_n_good_obs_al 0.0010339640776384474\n",
      "phot_rp_n_obs 0.0009490737791764423\n",
      "phot_bp_n_obs 0.0008696818648285564\n",
      "astrometric_excess_noise 0.0008602548787846038\n",
      "matched_observations 0.0008338672989656295\n",
      "astrometric_matched_observations 0.0008047697714521091\n",
      "visibility_periods_used 0.0007915417827028343\n",
      "astrometric_excess_noise_sig 0.0006521967268002723\n",
      "astrometric_n_bad_obs_al 0.0004716882316801103\n",
      "phot_proc_mode 0.00013233012416458877\n",
      "duplicated_source 5.141073759469903e-05\n",
      "astrometric_n_obs_ac 4.3971681740245565e-05\n",
      "astrometric_params_solved 0.0\n",
      "rv_nb_transits 0.0\n"
     ]
    }
   ],
   "source": [
    "importances = CL_best.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "keys = np.array(list(D[0].keys()))\n",
    "keys.sort()\n",
    "for i in indices:\n",
    "    print(keys[i],importances[i])\n",
    "pltkeys = keys[indices]\n",
    "pltimportances = importances[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest = 30\n",
    "bins = np.arange(-0.5,nbest-0.4,1.0)\n",
    "plt.hist(range(nbest),weights=pltimportances[:nbest],bins=bins,facecolor='None', alpha = 1.0, edgecolor= 'k',lw=1)\n",
    "plt.xticks(range(nbest), pltkeys[:nbest], rotation='vertical')\n",
    "# Pad margins so that markers don't get clipped by the axes\n",
    "plt.margins(0.5)\n",
    "# Tweak spacing to prevent clipping of tick-labels\n",
    "plt.subplots_adjust(bottom=0.5)\n",
    "plt.xlim([-0.5,nbest-0.5])\n",
    "plt.savefig('/Users/douglasboubert/Dropbox/ShowAndTell/GAIAhypervelocity/gaiabstar/result/machinelearning/importance.pdf')\n",
    "plt.savefig('/Users/douglasboubert/Dropbox/ShowAndTell/GAIAhypervelocity/gaiabstar/result/machinelearning/importance.png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simple plots\n",
    "type_plotting(np.log10(totalpm),gagabox['bp_rp'],PLOT=True,PLOTHVS=True,XSTR='log10(Total PM) (mas/yr)',YSTR='BP-RP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wdt in WDTYPES:\n",
    "    pltsub = np.where(np.array(wdclass) ==  wdt)\n",
    "    plt.scatter(gagawdbox['u_g0'][pltsub],gagawdbox['g_r0'][pltsub],label=wdt)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
